

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>James-Stein Encoder &mdash; Category Encoders 2.2.2 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Leave One Out" href="leaveoneout.html" />
    <link rel="prev" title="Helmert Coding" href="helmert.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> Category Encoders
          

          
          </a>

          
            
            
              <div class="version">
                2.2.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="backward_difference.html">Backward Difference Coding</a></li>
<li class="toctree-l1"><a class="reference internal" href="basen.html">BaseN</a></li>
<li class="toctree-l1"><a class="reference internal" href="binary.html">Binary</a></li>
<li class="toctree-l1"><a class="reference internal" href="catboost.html">CatBoost Encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="count.html">Count Encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="glmm.html">Generalized Linear Mixed Model Encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="hashing.html">Hashing</a></li>
<li class="toctree-l1"><a class="reference internal" href="helmert.html">Helmert Coding</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">James-Stein Encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="leaveoneout.html">Leave One Out</a></li>
<li class="toctree-l1"><a class="reference internal" href="mestimate.html">M-estimate</a></li>
<li class="toctree-l1"><a class="reference internal" href="onehot.html">One Hot</a></li>
<li class="toctree-l1"><a class="reference internal" href="ordinal.html">Ordinal</a></li>
<li class="toctree-l1"><a class="reference internal" href="polynomial.html">Polynomial Coding</a></li>
<li class="toctree-l1"><a class="reference internal" href="sum.html">Sum Coding</a></li>
<li class="toctree-l1"><a class="reference internal" href="targetencoder.html">Target Encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="woe.html">Weight of Evidence</a></li>
<li class="toctree-l1"><a class="reference internal" href="wrapper.html">Wrappers</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Category Encoders</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>James-Stein Encoder</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/jamesstein.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="james-stein-encoder">
<h1>James-Stein Encoder<a class="headerlink" href="#james-stein-encoder" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="category_encoders.james_stein.JamesSteinEncoder">
<em class="property">class </em><code class="sig-prename descclassname">category_encoders.james_stein.</code><code class="sig-name descname">JamesSteinEncoder</code><span class="sig-paren">(</span><em class="sig-param">verbose=0</em>, <em class="sig-param">cols=None</em>, <em class="sig-param">drop_invariant=False</em>, <em class="sig-param">return_df=True</em>, <em class="sig-param">handle_unknown='value'</em>, <em class="sig-param">handle_missing='value'</em>, <em class="sig-param">model='independent'</em>, <em class="sig-param">random_state=None</em>, <em class="sig-param">randomized=False</em>, <em class="sig-param">sigma=0.05</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/category_encoders/james_stein.html#JamesSteinEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#category_encoders.james_stein.JamesSteinEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>James-Stein estimator.</p>
<p>Supported targets: binomial and continuous. For polynomial target support, see PolynomialWrapper.</p>
<p>For feature value <cite>i</cite>, James-Stein estimator returns a weighted average of:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>The mean target value for the observed feature value <cite>i</cite>.</p></li>
<li><p>The mean target value (regardless of the feature value).</p></li>
</ol>
</div></blockquote>
<p>This can be written as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">JS_i</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">B</span><span class="p">)</span><span class="o">*</span><span class="n">mean</span><span class="p">(</span><span class="n">y_i</span><span class="p">)</span> <span class="o">+</span> <span class="n">B</span><span class="o">*</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>The question is, what should be the weight <cite>B</cite>?
If we put too much weight on the conditional mean value, we will overfit.
If we put too much weight on the global mean, we will underfit.
The canonical solution in machine learning is to perform cross-validation.
However, Charles Stein came with a closed-form solution to the problem.
The intuition is: If the estimate of <cite>mean(y_i)</cite> is unreliable (<cite>y_i</cite> has high variance),
we should put more weight on <cite>mean(y)</cite>. Stein put it into an equation as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">B</span> <span class="o">=</span> <span class="n">var</span><span class="p">(</span><span class="n">y_i</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">var</span><span class="p">(</span><span class="n">y_i</span><span class="p">)</span><span class="o">+</span><span class="n">var</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
<p>The only remaining issue is that we do not know <cite>var(y)</cite>, let alone <cite>var(y_i)</cite>.
Hence, we have to estimate the variances. But how can we reliably estimate the
variances, when we already struggle with the estimation of the mean values?!
There are multiple solutions:</p>
<blockquote>
<div><p>1. If we have the same count of observations for each feature value <cite>i</cite> and all
<cite>y_i</cite> are close to each other, we can pretend that all <cite>var(y_i)</cite> are identical.
This is called a pooled model.
2. If the observation counts are not equal, it makes sense to replace the variances
with squared standard errors, which penalize small observation counts:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SE</span><span class="o">^</span><span class="mi">2</span> <span class="o">=</span> <span class="n">var</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="n">count</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>This is called an independent model.</p>
</div></blockquote>
<p>James-Stein estimator has, however, one practical limitation - it was defined
only for normal distributions. If you want to apply it for binary classification,
which allows only values {0, 1}, it is better to first convert the mean target value
from the bound interval &lt;0,1&gt; into an unbounded interval by replacing mean(y)
with log-odds ratio:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">log</span><span class="o">-</span><span class="n">odds_ratio_i</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">y_i</span><span class="p">)</span><span class="o">/</span><span class="n">mean</span><span class="p">(</span><span class="n">y_not_i</span><span class="p">))</span>
</pre></div>
</div>
<p>This is called binary model. The estimation of parameters of this model is, however,
tricky and sometimes it fails fatally. In these situations, it is better to use beta
model, which generally delivers slightly worse accuracy than binary model but does
not suffer from fatal failures.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>verbose: int</strong></dt><dd><p>integer indicating verbosity of the output. 0 for none.</p>
</dd>
<dt><strong>cols: list</strong></dt><dd><p>a list of columns to encode, if None, all string columns will be encoded.</p>
</dd>
<dt><strong>drop_invariant: bool</strong></dt><dd><p>boolean for whether or not to drop encoded columns with 0 variance.</p>
</dd>
<dt><strong>return_df: bool</strong></dt><dd><p>boolean for whether to return a pandas DataFrame from transform (otherwise it will be a numpy array).</p>
</dd>
<dt><strong>handle_missing: str</strong></dt><dd><p>options are ‘return_nan’, ‘error’ and ‘value’, defaults to ‘value’, which returns the prior probability.</p>
</dd>
<dt><strong>handle_unknown: str</strong></dt><dd><p>options are ‘return_nan’, ‘error’ and ‘value’, defaults to ‘value’, which returns the prior probability.</p>
</dd>
<dt><strong>model: str</strong></dt><dd><p>options are ‘pooled’, ‘beta’, ‘binary’ and ‘independent’, defaults to ‘independent’.</p>
</dd>
<dt><strong>randomized: bool,</strong></dt><dd><p>adds normal (Gaussian) distribution noise into training data in order to decrease overfitting (testing data are untouched).</p>
</dd>
<dt><strong>sigma: float</strong></dt><dd><p>standard deviation (spread or “width”) of the normal distribution.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r50705e07df56-1"><span class="brackets">1</span></dt>
<dd><p>Parametric empirical Bayes inference: Theory and applications, equations 1.19 &amp; 1.20, from</p>
</dd>
</dl>
<p><a class="reference external" href="https://www.jstor.org/stable/2287098">https://www.jstor.org/stable/2287098</a></p>
<dl class="citation">
<dt class="label" id="r50705e07df56-2"><span class="brackets">2</span></dt>
<dd><p>Empirical Bayes for multiple sample sizes, from</p>
</dd>
</dl>
<p><a class="reference external" href="http://chris-said.io/2017/05/03/empirical-bayes-for-multiple-sample-sizes/">http://chris-said.io/2017/05/03/empirical-bayes-for-multiple-sample-sizes/</a></p>
<dl class="citation">
<dt class="label" id="r50705e07df56-3"><span class="brackets">3</span></dt>
<dd><p>Shrinkage Estimation of Log-odds Ratios for Comparing Mobility Tables, from</p>
</dd>
</dl>
<p><a class="reference external" href="https://journals.sagepub.com/doi/abs/10.1177/0081175015570097">https://journals.sagepub.com/doi/abs/10.1177/0081175015570097</a></p>
<dl class="citation">
<dt class="label" id="r50705e07df56-4"><span class="brackets">4</span></dt>
<dd><p>Stein’s paradox and group rationality, from</p>
</dd>
</dl>
<p><a class="reference external" href="http://www.philos.rug.nl/~romeyn/presentation/">http://www.philos.rug.nl/~romeyn/presentation/</a><a href="#id6"><span class="problematic" id="id7">2017_romeijn_</span></a>-_Paris_Stein.pdf</p>
<dl class="citation">
<dt class="label" id="r50705e07df56-5"><span class="brackets">5</span></dt>
<dd><p>Stein’s Paradox in Statistics, from</p>
</dd>
</dl>
<p><a class="reference external" href="http://statweb.stanford.edu/~ckirby/brad/other/Article1977.pdf">http://statweb.stanford.edu/~ckirby/brad/other/Article1977.pdf</a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.fit" title="category_encoders.james_stein.JamesSteinEncoder.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(X, y, **kwargs)</p></td>
<td><p>Fit encoder according to X and binary y.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code>(X[, y])</p></td>
<td><p>Encoders that utilize the target must make sure that the training data are transformed with:</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.get_feature_names" title="category_encoders.james_stein.JamesSteinEncoder.get_feature_names"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_feature_names</span></code></a>()</p></td>
<td><p>Returns the names of all transformed / added columns.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.transform" title="category_encoders.james_stein.JamesSteinEncoder.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(X[, y, override_return_df])</p></td>
<td><p>Perform the transformation to new categorical data.</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="category_encoders.james_stein.JamesSteinEncoder.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">y</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/category_encoders/james_stein.html#JamesSteinEncoder.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#category_encoders.james_stein.JamesSteinEncoder.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit encoder according to X and binary y.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape = [n_samples, n_features]</span></dt><dd><p>Training vectors, where n_samples is the number of samples
and n_features is the number of features.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like, shape = [n_samples]</span></dt><dd><p>Binary target values.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">encoder</span></dt><dd><p>Returns self.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="category_encoders.james_stein.JamesSteinEncoder.get_feature_names">
<code class="sig-name descname">get_feature_names</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/category_encoders/james_stein.html#JamesSteinEncoder.get_feature_names"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#category_encoders.james_stein.JamesSteinEncoder.get_feature_names" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the names of all transformed / added columns.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><dl class="simple">
<dt>feature_names: list</dt><dd><p>A list with all feature names transformed or added.
Note: potentially dropped features are not included!</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="category_encoders.james_stein.JamesSteinEncoder.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">y=None</em>, <em class="sig-param">override_return_df=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/category_encoders/james_stein.html#JamesSteinEncoder.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#category_encoders.james_stein.JamesSteinEncoder.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform the transformation to new categorical data. When the data are used for model training,
it is important to also pass the target in order to apply leave one out.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape = [n_samples, n_features]</span></dt><dd></dd>
<dt><strong>y</strong><span class="classifier">array-like, shape = [n_samples] when transform by leave one out</span></dt><dd><p>None, when transform without target information (such as transform test set)</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>p</strong><span class="classifier">array, shape = [n_samples, n_numeric + N]</span></dt><dd><p>Transformed values with encoding applied.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="leaveoneout.html" class="btn btn-neutral float-right" title="Leave One Out" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="helmert.html" class="btn btn-neutral float-left" title="Helmert Coding" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2016, Will McGinnis

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>