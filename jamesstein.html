<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>James-Stein Encoder &mdash; Category Encoders 2.6.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Leave One Out" href="leaveoneout.html" />
    <link rel="prev" title="Helmert Coding" href="helmert.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Category Encoders
          </a>
              <div class="version">
                2.6.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="backward_difference.html">Backward Difference Coding</a></li>
<li class="toctree-l1"><a class="reference internal" href="basen.html">BaseN</a></li>
<li class="toctree-l1"><a class="reference internal" href="binary.html">Binary</a></li>
<li class="toctree-l1"><a class="reference internal" href="catboost.html">CatBoost Encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="count.html">Count Encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="glmm.html">Generalized Linear Mixed Model Encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="gray.html">Gray</a></li>
<li class="toctree-l1"><a class="reference internal" href="hashing.html">Hashing</a></li>
<li class="toctree-l1"><a class="reference internal" href="helmert.html">Helmert Coding</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">James-Stein Encoder</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder"><code class="docutils literal notranslate"><span class="pre">JamesSteinEncoder</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.fit"><code class="docutils literal notranslate"><span class="pre">JamesSteinEncoder.fit()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.fit_transform"><code class="docutils literal notranslate"><span class="pre">JamesSteinEncoder.fit_transform()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.get_feature_names_in"><code class="docutils literal notranslate"><span class="pre">JamesSteinEncoder.get_feature_names_in()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.get_feature_names_out"><code class="docutils literal notranslate"><span class="pre">JamesSteinEncoder.get_feature_names_out()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.get_params"><code class="docutils literal notranslate"><span class="pre">JamesSteinEncoder.get_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.set_output"><code class="docutils literal notranslate"><span class="pre">JamesSteinEncoder.set_output()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.set_params"><code class="docutils literal notranslate"><span class="pre">JamesSteinEncoder.set_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.transform"><code class="docutils literal notranslate"><span class="pre">JamesSteinEncoder.transform()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="leaveoneout.html">Leave One Out</a></li>
<li class="toctree-l1"><a class="reference internal" href="mestimate.html">M-estimate</a></li>
<li class="toctree-l1"><a class="reference internal" href="onehot.html">One Hot</a></li>
<li class="toctree-l1"><a class="reference internal" href="ordinal.html">Ordinal</a></li>
<li class="toctree-l1"><a class="reference internal" href="polynomial.html">Polynomial Coding</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantile.html">Quantile Encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="rankhot.html">RankHotEncoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="sum.html">Sum Coding</a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary Encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="targetencoder.html">Target Encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="woe.html">Weight of Evidence</a></li>
<li class="toctree-l1"><a class="reference internal" href="wrapper.html">Wrappers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Category Encoders</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">James-Stein Encoder</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/jamesstein.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="james-stein-encoder">
<h1>James-Stein Encoder<a class="headerlink" href="#james-stein-encoder" title="Permalink to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="category_encoders.james_stein.JamesSteinEncoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">category_encoders.james_stein.</span></span><span class="sig-name descname"><span class="pre">JamesSteinEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_invariant</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_df</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">handle_unknown</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'value'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">handle_missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'value'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'independent'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">randomized</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/category_encoders/james_stein.html#JamesSteinEncoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#category_encoders.james_stein.JamesSteinEncoder" title="Permalink to this definition"></a></dt>
<dd><p>James-Stein estimator.</p>
<p>Supported targets: binomial and continuous. For polynomial target support, see PolynomialWrapper.</p>
<p>For feature value <cite>i</cite>, James-Stein estimator returns a weighted average of:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>The mean target value for the observed feature value <cite>i</cite>.</p></li>
<li><p>The mean target value (regardless of the feature value).</p></li>
</ol>
</div></blockquote>
<p>This can be written as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">JS_i</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">B</span><span class="p">)</span><span class="o">*</span><span class="n">mean</span><span class="p">(</span><span class="n">y_i</span><span class="p">)</span> <span class="o">+</span> <span class="n">B</span><span class="o">*</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>The question is, what should be the weight <cite>B</cite>?
If we put too much weight on the conditional mean value, we will overfit.
If we put too much weight on the global mean, we will underfit.
The canonical solution in machine learning is to perform cross-validation.
However, Charles Stein came with a closed-form solution to the problem.
The intuition is: If the estimate of <cite>mean(y_i)</cite> is unreliable (<cite>y_i</cite> has high variance),
we should put more weight on <cite>mean(y)</cite>. Stein put it into an equation as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">B</span> <span class="o">=</span> <span class="n">var</span><span class="p">(</span><span class="n">y_i</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">var</span><span class="p">(</span><span class="n">y_i</span><span class="p">)</span><span class="o">+</span><span class="n">var</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
<p>The only remaining issue is that we do not know <cite>var(y)</cite>, let alone <cite>var(y_i)</cite>.
Hence, we have to estimate the variances. But how can we reliably estimate the
variances, when we already struggle with the estimation of the mean values?!
There are multiple solutions:</p>
<blockquote>
<div><p>1. If we have the same count of observations for each feature value <cite>i</cite> and all
<cite>y_i</cite> are close to each other, we can pretend that all <cite>var(y_i)</cite> are identical.
This is called a pooled model.
2. If the observation counts are not equal, it makes sense to replace the variances
with squared standard errors, which penalize small observation counts:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SE</span><span class="o">^</span><span class="mi">2</span> <span class="o">=</span> <span class="n">var</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="n">count</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>This is called an independent model.</p>
</div></blockquote>
<p>James-Stein estimator has, however, one practical limitation - it was defined
only for normal distributions. If you want to apply it for binary classification,
which allows only values {0, 1}, it is better to first convert the mean target value
from the bound interval &lt;0,1&gt; into an unbounded interval by replacing mean(y)
with log-odds ratio:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">log</span><span class="o">-</span><span class="n">odds_ratio_i</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">y_i</span><span class="p">)</span><span class="o">/</span><span class="n">mean</span><span class="p">(</span><span class="n">y_not_i</span><span class="p">))</span>
</pre></div>
</div>
<p>This is called binary model. The estimation of parameters of this model is, however,
tricky and sometimes it fails fatally. In these situations, it is better to use beta
model, which generally delivers slightly worse accuracy than binary model but does
not suffer from fatal failures.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>verbose: int</strong></dt><dd><p>integer indicating verbosity of the output. 0 for none.</p>
</dd>
<dt><strong>cols: list</strong></dt><dd><p>a list of columns to encode, if None, all string columns will be encoded.</p>
</dd>
<dt><strong>drop_invariant: bool</strong></dt><dd><p>boolean for whether or not to drop encoded columns with 0 variance.</p>
</dd>
<dt><strong>return_df: bool</strong></dt><dd><p>boolean for whether to return a pandas DataFrame from transform (otherwise it will be a numpy array).</p>
</dd>
<dt><strong>handle_missing: str</strong></dt><dd><p>options are ‘return_nan’, ‘error’ and ‘value’, defaults to ‘value’, which returns the prior probability.</p>
</dd>
<dt><strong>handle_unknown: str</strong></dt><dd><p>options are ‘return_nan’, ‘error’ and ‘value’, defaults to ‘value’, which returns the prior probability.</p>
</dd>
<dt><strong>model: str</strong></dt><dd><p>options are ‘pooled’, ‘beta’, ‘binary’ and ‘independent’, defaults to ‘independent’.</p>
</dd>
<dt><strong>randomized: bool,</strong></dt><dd><p>adds normal (Gaussian) distribution noise into training data in order to decrease overfitting (testing data are untouched).</p>
</dd>
<dt><strong>sigma: float</strong></dt><dd><p>standard deviation (spread or “width”) of the normal distribution.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r50705e07df56-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Parametric empirical Bayes inference: Theory and applications, equations 1.19 &amp; 1.20, from</p>
</div>
</div>
<p><a class="reference external" href="https://www.jstor.org/stable/2287098">https://www.jstor.org/stable/2287098</a></p>
<div role="list" class="citation-list">
<div class="citation" id="r50705e07df56-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Empirical Bayes for multiple sample sizes, from</p>
</div>
</div>
<p><a class="reference external" href="http://chris-said.io/2017/05/03/empirical-bayes-for-multiple-sample-sizes/">http://chris-said.io/2017/05/03/empirical-bayes-for-multiple-sample-sizes/</a></p>
<div role="list" class="citation-list">
<div class="citation" id="r50705e07df56-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>Shrinkage Estimation of Log-odds Ratios for Comparing Mobility Tables, from</p>
</div>
</div>
<p><a class="reference external" href="https://journals.sagepub.com/doi/abs/10.1177/0081175015570097">https://journals.sagepub.com/doi/abs/10.1177/0081175015570097</a></p>
<div role="list" class="citation-list">
<div class="citation" id="r50705e07df56-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>Stein’s paradox and group rationality, from</p>
</div>
</div>
<p><a class="reference external" href="http://www.philos.rug.nl/~romeyn/presentation/">http://www.philos.rug.nl/~romeyn/presentation/</a><a href="#id6"><span class="problematic" id="id7">2017_romeijn_</span></a>-_Paris_Stein.pdf</p>
<div role="list" class="citation-list">
<div class="citation" id="r50705e07df56-5" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></span>
<p>Stein’s Paradox in Statistics, from</p>
</div>
</div>
<p><a class="reference external" href="http://statweb.stanford.edu/~ckirby/brad/other/Article1977.pdf">http://statweb.stanford.edu/~ckirby/brad/other/Article1977.pdf</a></p>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.fit" title="category_encoders.james_stein.JamesSteinEncoder.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(X[, y])</p></td>
<td><p>Fits the encoder according to X and y.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.fit_transform" title="category_encoders.james_stein.JamesSteinEncoder.fit_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code></a>(X[, y])</p></td>
<td><p>Encoders that utilize the target must make sure that the training data are transformed with:</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.get_feature_names_in" title="category_encoders.james_stein.JamesSteinEncoder.get_feature_names_in"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_feature_names_in</span></code></a>()</p></td>
<td><p>Returns the names of all input columns present when fitting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.get_feature_names_out" title="category_encoders.james_stein.JamesSteinEncoder.get_feature_names_out"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_feature_names_out</span></code></a>([input_features])</p></td>
<td><p>Returns the names of all transformed / added columns.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.get_params" title="category_encoders.james_stein.JamesSteinEncoder.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.set_output" title="category_encoders.james_stein.JamesSteinEncoder.set_output"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_output</span></code></a>(*[, transform])</p></td>
<td><p>Set output container.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.set_params" title="category_encoders.james_stein.JamesSteinEncoder.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.transform" title="category_encoders.james_stein.JamesSteinEncoder.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(X[, y, override_return_df])</p></td>
<td><p>Perform the transformation to new categorical data.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><strong>get_feature_names</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>verbose: int</strong></dt><dd><p>integer indicating verbosity of output. 0 for none.</p>
</dd>
<dt><strong>cols: list</strong></dt><dd><p>a list of columns to encode, if None, all string and categorical columns
will be encoded.</p>
</dd>
<dt><strong>drop_invariant: bool</strong></dt><dd><p>boolean for whether or not to drop columns with 0 variance.</p>
</dd>
<dt><strong>return_df: bool</strong></dt><dd><p>boolean for whether to return a pandas DataFrame from transform and inverse transform
(otherwise it will be a numpy array).</p>
</dd>
<dt><strong>handle_missing: str</strong></dt><dd><p>how to handle missing values at fit time. Options are ‘error’, ‘return_nan’,
and ‘value’. Default ‘value’, which treat NaNs as a countable category at
fit time.</p>
</dd>
<dt><strong>handle_unknown: str, int or dict of {column</strong><span class="classifier">option, …}.</span></dt><dd><p>how to handle unknown labels at transform time. Options are ‘error’
‘return_nan’, ‘value’ and int. Defaults to None which uses NaN behaviour
specified at fit time. Passing an int will fill with this int value.</p>
</dd>
<dt><strong>kwargs: dict.</strong></dt><dd><p>additional encoder specific parameters like regularisation.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.fit" title="category_encoders.james_stein.JamesSteinEncoder.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(X[, y])</p></td>
<td><p>Fits the encoder according to X and y.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.fit_transform" title="category_encoders.james_stein.JamesSteinEncoder.fit_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code></a>(X[, y])</p></td>
<td><p>Encoders that utilize the target must make sure that the training data are transformed with:</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.get_feature_names_in" title="category_encoders.james_stein.JamesSteinEncoder.get_feature_names_in"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_feature_names_in</span></code></a>()</p></td>
<td><p>Returns the names of all input columns present when fitting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.get_feature_names_out" title="category_encoders.james_stein.JamesSteinEncoder.get_feature_names_out"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_feature_names_out</span></code></a>([input_features])</p></td>
<td><p>Returns the names of all transformed / added columns.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.get_params" title="category_encoders.james_stein.JamesSteinEncoder.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.set_output" title="category_encoders.james_stein.JamesSteinEncoder.set_output"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_output</span></code></a>(*[, transform])</p></td>
<td><p>Set output container.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.set_params" title="category_encoders.james_stein.JamesSteinEncoder.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#category_encoders.james_stein.JamesSteinEncoder.transform" title="category_encoders.james_stein.JamesSteinEncoder.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(X[, y, override_return_df])</p></td>
<td><p>Perform the transformation to new categorical data.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><strong>get_feature_names</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="category_encoders.james_stein.JamesSteinEncoder.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#category_encoders.james_stein.JamesSteinEncoder.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fits the encoder according to X and y.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape = [n_samples, n_features]</span></dt><dd><p>Training vectors, where n_samples is the number of samples
and n_features is the number of features.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like, shape = [n_samples]</span></dt><dd><p>Target values.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">encoder</span></dt><dd><p>Returns self.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="category_encoders.james_stein.JamesSteinEncoder.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">fit_params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#category_encoders.james_stein.JamesSteinEncoder.fit_transform" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Encoders that utilize the target must make sure that the training data are transformed with:</dt><dd><p>transform(X, y)</p>
</dd>
<dt>and not with:</dt><dd><p>transform(X)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="category_encoders.james_stein.JamesSteinEncoder.get_feature_names_in">
<span class="sig-name descname"><span class="pre">get_feature_names_in</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#category_encoders.james_stein.JamesSteinEncoder.get_feature_names_in" title="Permalink to this definition"></a></dt>
<dd><p>Returns the names of all input columns present when fitting.
These columns are necessary for the transform step.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="category_encoders.james_stein.JamesSteinEncoder.get_feature_names_out">
<span class="sig-name descname"><span class="pre">get_feature_names_out</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#category_encoders.james_stein.JamesSteinEncoder.get_feature_names_out" title="Permalink to this definition"></a></dt>
<dd><p>Returns the names of all transformed / added columns.</p>
<p>Note that in sklearn the get_feature_names_out function takes the feature_names_in as an argument
and determines the output feature names using the input. A fit is usually not necessary and if so a
NotFittedError is raised.
We just require a fit all the time and return the fitted output columns.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>feature_names: np.ndarray</dt><dd><p>A numpy array with all feature names transformed or added.
Note: potentially dropped features (because the feature is constant/invariant) are not included!</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="category_encoders.james_stein.JamesSteinEncoder.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#category_encoders.james_stein.JamesSteinEncoder.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="category_encoders.james_stein.JamesSteinEncoder.set_output">
<span class="sig-name descname"><span class="pre">set_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#category_encoders.james_stein.JamesSteinEncoder.set_output" title="Permalink to this definition"></a></dt>
<dd><p>Set output container.</p>
<p>See <span class="xref std std-ref">sphx_glr_auto_examples_miscellaneous_plot_set_output.py</span>
for an example on how to use the API.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>transform</strong><span class="classifier">{“default”, “pandas”}, default=None</span></dt><dd><p>Configure output of <cite>transform</cite> and <cite>fit_transform</cite>.</p>
<ul class="simple">
<li><p><cite>“default”</cite>: Default output format of a transformer</p></li>
<li><p><cite>“pandas”</cite>: DataFrame output</p></li>
<li><p><cite>None</cite>: Transform configuration is unchanged</p></li>
</ul>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">estimator instance</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="category_encoders.james_stein.JamesSteinEncoder.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#category_encoders.james_stein.JamesSteinEncoder.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>). The latter have
parameters of the form <code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s
possible to update each component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Estimator parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">estimator instance</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="category_encoders.james_stein.JamesSteinEncoder.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">override_return_df</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#category_encoders.james_stein.JamesSteinEncoder.transform" title="Permalink to this definition"></a></dt>
<dd><p>Perform the transformation to new categorical data.</p>
<p>Some encoders behave differently on whether y is given or not. This is mainly due to regularisation
in order to avoid overfitting.
On training data transform should be called with y, on test data without.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape = [n_samples, n_features]</span></dt><dd></dd>
<dt><strong>y</strong><span class="classifier">array-like, shape = [n_samples] or None</span></dt><dd></dd>
<dt><strong>override_return_df</strong><span class="classifier">bool</span></dt><dd><p>override self.return_df to force to return a data frame</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>p</strong><span class="classifier">array or DataFrame, shape = [n_samples, n_features_out]</span></dt><dd><p>Transformed values with encoding applied.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="helmert.html" class="btn btn-neutral float-left" title="Helmert Coding" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="leaveoneout.html" class="btn btn-neutral float-right" title="Leave One Out" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Will McGinnis.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>